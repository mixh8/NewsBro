On Friday, OpenAI fired CEO Sam Altman in a surprise move that led to the resignation of President Greg Brockman and three senior scientists. The move also blindsided key investor and minority owner Microsoft, reportedly making CEO Satya Nadella furious. As Friday night wore on, reports emerged that the ousting was likely orchestrated by Chief Scientist Ilya Sutskever over concerns about the safety and speed of OpenAI's tech deployment.
"This was the board doing its duty to the mission of the nonprofit, which is to make sure that OpenAI builds AGI that benefits all of humanity," Sutskever told employees at an emergency all-hands meeting on Friday afternoon, as reported by The Information.
Since its founding, OpenAI has pursued the development of artificial general intelligence (or AGI), which is a hypothetical technology that would be able to perform any intellectual task a human can do, potentially replacing a large number of humans at their jobs.

Internally at OpenAI, insiders say that disagreements had emerged over the speed at which Altman was pushing for commercialization and company growth, with Sutskever arguing to slow things down. Sources told reporter Kara Swisher that OpenAI's Dev Day event on November 6, with Altman front and center in a keynote pushing consumer-like products, was an "inflection moment of Altman pushing too far, too fast."

In a joint statement released Friday night, Altman and Brockman said they were "shocked and saddened" by the board's actions. And they weren't the only ones shocked by the news, as tech insiders took to social media on Friday to share their reactions. Angel investor Ron Conway wrote, "What happened at OpenAI today is a Board coup that we have not seen the likes of since 1985 when the then-Apple board pushed out Steve Jobs. It is shocking; it is irresponsible; and it does not do right by Sam & Greg or all the builders in OpenAI."

OpenAI has an unusual structure where its for-profit arm is owned and controlled by a non-profit 501(c)(3) public charity. Prior to yesterday, that non-profit was controlled by a board of directors that included Altman, Brockman, Ilya Sutskever and three others who were not OpenAI employees: Adam D’Angelo, the CEO of Quora; Tasha McCauley, an adjunct senior management scientist at RAND corporation; and Helen Toner, director of strategy and foundational research grants at Georgetown’s Center for Security and Emerging Technology. Now, only Sutskever, D'Angelo, McCauley, and Toner remain.
According to the joint statement from Brockman and Altman, Altman's firing came as a complete surprise to the pair, and they laid out a rough timeline of what happened. On Thursday night, Altman was asked to attend a remote board meeting on Friday at noon. The next day, Brockman, who was Chairman of the OpenAI board, was not invited to this board meeting, where Altman was fired.
Around 30 minutes later, Brockman was informed by Sutskever that he was being removed from his board role but could remain at the company, and that Altman had been fired (Brockman declined, and resigned his role later on Friday). According to Brockman, the OpenAI management team was only made aware of these moves shortly after the fact, but former CTO (now interim CEO) Mira Murati had been informed on Thursday night.
Key questions remain about accusations made against Altman in the OpenAI blog post that announced his departure, where the board said that Altman "was not consistently candid in his communications with the board, hindering its ability to exercise its responsibilities." That has yet to be clarified by the company, but insiders say the move was mostly a power play that resulted from a cultural schism between Altman and Sutskever over Altman's management style and drive for high-profile publicity. On September 29, Sutskever tweeted, "Ego is the enemy of growth."

The schism is causing further turmoil on the inside. Three AI researchers loyal to Altman departed the company as well on Friday, resigning in reaction to the news: Jakub Pachocki, GPT-4 lead and OpenAI's director of research; Aleksander Madry, head of a team evaluating AI risk, and Szymon Sidor, an open source baselines researcher.

Pushing back the "veil of ignorance"
Rumors have already begun swirling about potential internal breakthroughs at OpenAI that may have intensified the slow/fast rift within the company, owing to Sutskever's role as co-lead of a "Superalignment" team that is tasked with figuring out how to control hypothetical superintelligent AI. At the APEC CEO Summit on Thursday, Altman said, "Four times now in the history of OpenAI—the most recent time was just in the last couple of weeks—I’ve gotten to be in the room when we push the veil of ignorance back and the frontier of discovery forward. And getting to do that is like the professional honor of a lifetime."
The concern here not necessarily being that OpenAI has developed superintelligence, which experts say is unlikely, but that the new breakthrough Altman mentioned may have added pressure to a company that is fighting within itself to proceed safely (from its non-profit branch) but also make money (from its for-profit subsidiary). Altman also recently said that GPT-5, presumed to be a powerful successor to the alarm-causing GPT-4, is now in development.

As news spread, some predictably shared quips on social media. X user shaurya wrote, "this is like the roman empire for people who do matrix multiplication." And AI futurist Daniel Jeffries said, "The entire AI industry would like to thank the OpenAI board for giving us all a chance to catch up."

But not all reactions were doom and gloom. As Friday night wore on, some at OpenAI made forward-looking statements. Evan Morikawa, Engineering Manager at OpenAI wrote on X, "For those wondering what’ll happen next, the answer is we’ll keep shipping. @sama & @gdb weren’t micro-managers. The ✨ comes from the many geniuses here in research product eng & design. There’s clear internal uniformity among these leaders that we’re here for the bigger mission."

